{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e56c00f7",
   "metadata": {},
   "source": [
    "## 프로그램 4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc51d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 퍼셉트론의 매개변수:  [[2. 2.]] [-1.]\n",
      "훈련집합에 대한 예측:  [-1  1  1  1]\n",
      "정확률 측정:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# 훈련 집합 구축\n",
    "X=[[0,0],[0,1],[1,0],[1,1]]\n",
    "y=[-1,1,1,1]\n",
    "\n",
    "# fit 함수로 Perceptron 학습\n",
    "p=Perceptron()\n",
    "p.fit(X,y)\n",
    "\n",
    "print(\"학습된 퍼셉트론의 매개변수: \",p.coef_,p.intercept_)\n",
    "print(\"훈련집합에 대한 예측: \",p.predict(X))\n",
    "print(\"정확률 측정: \",p.score(X,y)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7963a5ea",
   "metadata": {},
   "source": [
    "## 프로그램 4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8a378c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74.  0.  0.  1.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0. 71.  0.  1.  1.  0.  0.  0.  2.  1.]\n",
      " [ 0.  0. 57.  1.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 69.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. 73.  0.  0.  2.  0.  1.]\n",
      " [ 0.  0.  0.  6.  0. 74.  0.  0.  4.  3.]\n",
      " [ 0.  0.  0.  0.  0.  0. 68.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.  0. 72.  0.  0.]\n",
      " [ 0.  4.  1.  3.  0.  0.  0.  1. 54.  3.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  1. 65.]]\n",
      "테스트 집합에 대한 정확률은  94.1585535465925 %입니다.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋을 읽고 훈련 집합과 테스트 집합으로 분할\n",
    "digit=datasets.load_digits()\n",
    "x_train,x_test,y_train,y_test=train_test_split(digit.data,digit.target,train_size=0.6)\n",
    "\n",
    "# fit 함수로 Perceptron 학습\n",
    "p=Perceptron(max_iter=100,eta0=0.001,verbose=0)\n",
    "p.fit(x_train,y_train) # digit 데이터로 모델링\n",
    "\n",
    "res=p.predict(x_test) # 테스트 집합으로 예측\n",
    "\n",
    "# 혼동 행렬\n",
    "conf = np.zeros((10,10))\n",
    "for i in range(len(res)):\n",
    "  conf[res[i]][y_test[i]]+=1\n",
    "print(conf)\n",
    "\n",
    "# 정확률 계산\n",
    "no_correct=0\n",
    "for i in range(10):\n",
    "  no_correct+=conf[i][i]\n",
    "accuracy=no_correct/len(res)\n",
    "print(\"테스트 집합에 대한 정확률은 \", accuracy*100, \"%입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289e3902",
   "metadata": {},
   "source": [
    "## 프로그램 4-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6f082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.67836338\n",
      "Iteration 2, loss = 0.36611994\n",
      "Iteration 3, loss = 0.22904201\n",
      "Iteration 4, loss = 0.16903384\n",
      "Iteration 5, loss = 0.13939671\n",
      "Iteration 6, loss = 0.12380159\n",
      "Iteration 7, loss = 0.10347594\n",
      "Iteration 8, loss = 0.08927241\n",
      "Iteration 9, loss = 0.07931753\n",
      "Iteration 10, loss = 0.07408064\n",
      "Iteration 11, loss = 0.06417802\n",
      "Iteration 12, loss = 0.06041626\n",
      "Iteration 13, loss = 0.05287654\n",
      "Iteration 14, loss = 0.04922784\n",
      "Iteration 15, loss = 0.04848040\n",
      "Iteration 16, loss = 0.04163654\n",
      "Iteration 17, loss = 0.03981027\n",
      "Iteration 18, loss = 0.03769853\n",
      "Iteration 19, loss = 0.03673709\n",
      "Iteration 20, loss = 0.03319501\n",
      "Iteration 21, loss = 0.03276407\n",
      "Iteration 22, loss = 0.03067316\n",
      "Iteration 23, loss = 0.02955343\n",
      "Iteration 24, loss = 0.02756618\n",
      "Iteration 25, loss = 0.02606796\n",
      "Iteration 26, loss = 0.02625540\n",
      "Iteration 27, loss = 0.02420818\n",
      "Iteration 28, loss = 0.02309391\n",
      "Iteration 29, loss = 0.02264257\n",
      "Iteration 30, loss = 0.02119286\n",
      "Iteration 31, loss = 0.02125446\n",
      "Iteration 32, loss = 0.01984575\n",
      "Iteration 33, loss = 0.01879050\n",
      "Iteration 34, loss = 0.01843468\n",
      "Iteration 35, loss = 0.01783760\n",
      "Iteration 36, loss = 0.01710595\n",
      "Iteration 37, loss = 0.01637634\n",
      "Iteration 38, loss = 0.01672095\n",
      "Iteration 39, loss = 0.01592643\n",
      "Iteration 40, loss = 0.01528688\n",
      "Iteration 41, loss = 0.01495624\n",
      "Iteration 42, loss = 0.01456458\n",
      "Iteration 43, loss = 0.01406625\n",
      "Iteration 44, loss = 0.01377404\n",
      "Iteration 45, loss = 0.01352791\n",
      "Iteration 46, loss = 0.01297349\n",
      "Iteration 47, loss = 0.01291472\n",
      "Iteration 48, loss = 0.01237355\n",
      "Iteration 49, loss = 0.01208863\n",
      "Iteration 50, loss = 0.01222238\n",
      "Iteration 51, loss = 0.01165845\n",
      "Iteration 52, loss = 0.01145537\n",
      "Iteration 53, loss = 0.01121839\n",
      "Iteration 54, loss = 0.01097279\n",
      "Iteration 55, loss = 0.01072861\n",
      "Iteration 56, loss = 0.01050990\n",
      "Iteration 57, loss = 0.01050119\n",
      "Iteration 58, loss = 0.01041737\n",
      "Iteration 59, loss = 0.00993622\n",
      "Iteration 60, loss = 0.00987557\n",
      "Iteration 61, loss = 0.00953743\n",
      "Iteration 62, loss = 0.00947383\n",
      "Iteration 63, loss = 0.00923901\n",
      "Iteration 64, loss = 0.00909861\n",
      "Iteration 65, loss = 0.00901196\n",
      "Iteration 66, loss = 0.00867756\n",
      "Iteration 67, loss = 0.00872100\n",
      "Iteration 68, loss = 0.00838002\n",
      "Iteration 69, loss = 0.00843454\n",
      "Iteration 70, loss = 0.00819406\n",
      "Iteration 71, loss = 0.00823838\n",
      "Iteration 72, loss = 0.00800173\n",
      "Iteration 73, loss = 0.00796420\n",
      "Iteration 74, loss = 0.00781235\n",
      "Iteration 75, loss = 0.00766804\n",
      "Iteration 76, loss = 0.00752842\n",
      "Iteration 77, loss = 0.00750518\n",
      "Iteration 78, loss = 0.00730865\n",
      "Iteration 79, loss = 0.00721779\n",
      "Iteration 80, loss = 0.00725823\n",
      "Iteration 81, loss = 0.00702543\n",
      "Iteration 82, loss = 0.00693019\n",
      "Iteration 83, loss = 0.00686675\n",
      "Iteration 84, loss = 0.00683808\n",
      "Iteration 85, loss = 0.00664742\n",
      "Iteration 86, loss = 0.00657528\n",
      "Iteration 87, loss = 0.00650609\n",
      "Iteration 88, loss = 0.00638743\n",
      "Iteration 89, loss = 0.00643906\n",
      "Iteration 90, loss = 0.00627472\n",
      "Iteration 91, loss = 0.00620930\n",
      "Iteration 92, loss = 0.00613887\n",
      "Iteration 93, loss = 0.00608210\n",
      "Iteration 94, loss = 0.00597993\n",
      "Iteration 95, loss = 0.00596529\n",
      "Iteration 96, loss = 0.00580289\n",
      "Iteration 97, loss = 0.00581180\n",
      "Iteration 98, loss = 0.00567576\n",
      "Iteration 99, loss = 0.00570889\n",
      "Iteration 100, loss = 0.00555299\n",
      "Iteration 101, loss = 0.00557283\n",
      "Iteration 102, loss = 0.00547884\n",
      "Iteration 103, loss = 0.00541395\n",
      "Iteration 104, loss = 0.00537630\n",
      "Iteration 105, loss = 0.00531721\n",
      "Iteration 106, loss = 0.00521731\n",
      "Iteration 107, loss = 0.00517489\n",
      "Iteration 108, loss = 0.00520769\n",
      "Iteration 109, loss = 0.00508486\n",
      "Iteration 110, loss = 0.00502264\n",
      "Iteration 111, loss = 0.00502181\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "[[73.  0.  0.  0.  0.  0.  2.  0.  0.  0.]\n",
      " [ 0. 68.  1.  0.  0.  1.  0.  0.  1.  2.]\n",
      " [ 1.  0. 73.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 79.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0. 72.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0. 77.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  1. 70.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 66.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0. 57.  2.]\n",
      " [ 0.  0.  0.  0.  0.  2.  0.  0.  0. 65.]]\n",
      "테스트 집합에 대한 정확률은 97.35744089012516 %입니다.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋을 읽고 훈련 집합과 테스트 집합으로 분할\n",
    "digit=datasets.load_digits()\n",
    "x_train, x_test,y_train, y_test = train_test_split(digit.data, digit.target, train_size=0.6)\n",
    "\n",
    "# MLP 분류기 모델을 학습\n",
    "mlp=MLPClassifier(hidden_layer_sizes=(100),learning_rate_init=0.001,batch_size=32,max_iter=300,solver='sgd',verbose=True)\n",
    "mlp.fit(x_train,y_train)\n",
    "\n",
    "res=mlp.predict(x_test) # 테스트 집합으로 예측\n",
    "\n",
    "# 혼동 행렬\n",
    "conf=np.zeros((10,10))\n",
    "for i in range(len(res)):\n",
    "  conf[res[i]][y_test[i]]+=1\n",
    "print(conf)\n",
    "\n",
    "# 정확률 계산\n",
    "no_correct=0\n",
    "for i in range(10):\n",
    "  no_correct += conf[i][i]\n",
    "accuracy=no_correct/len(res)\n",
    "print(\"테스트 집합에 대한 정확률은\",accuracy*100,\"%입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371092a8",
   "metadata": {},
   "source": [
    "## 프로그램 4-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6acd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.61463496\n",
      "Iteration 2, loss = 0.27159111\n",
      "Iteration 3, loss = 0.21751755\n",
      "Iteration 4, loss = 0.18260255\n",
      "Iteration 5, loss = 0.15573768\n",
      "Iteration 6, loss = 0.13554610\n",
      "Iteration 7, loss = 0.11944608\n",
      "Iteration 8, loss = 0.10621055\n",
      "Iteration 9, loss = 0.09574005\n",
      "Iteration 10, loss = 0.08717076\n",
      "Iteration 11, loss = 0.07906800\n",
      "Iteration 12, loss = 0.07266975\n",
      "Iteration 13, loss = 0.06632582\n",
      "Iteration 14, loss = 0.06129815\n",
      "Iteration 15, loss = 0.05620858\n",
      "Iteration 16, loss = 0.05269518\n",
      "Iteration 17, loss = 0.04841899\n",
      "Iteration 18, loss = 0.04527787\n",
      "Iteration 19, loss = 0.04182196\n",
      "Iteration 20, loss = 0.03923059\n",
      "Iteration 21, loss = 0.03604967\n",
      "Iteration 22, loss = 0.03356163\n",
      "Iteration 23, loss = 0.03076387\n",
      "Iteration 24, loss = 0.02878379\n",
      "Iteration 25, loss = 0.02705454\n",
      "Iteration 26, loss = 0.02534963\n",
      "Iteration 27, loss = 0.02352654\n",
      "Iteration 28, loss = 0.02173879\n",
      "Iteration 29, loss = 0.02077634\n",
      "Iteration 30, loss = 0.01973860\n",
      "Iteration 31, loss = 0.01767591\n",
      "Iteration 32, loss = 0.01708563\n",
      "Iteration 33, loss = 0.01537297\n",
      "Iteration 34, loss = 0.01475733\n",
      "Iteration 35, loss = 0.01318890\n",
      "Iteration 36, loss = 0.01300561\n",
      "Iteration 37, loss = 0.01186731\n",
      "Iteration 38, loss = 0.01087007\n",
      "Iteration 39, loss = 0.00982200\n",
      "Iteration 40, loss = 0.00943545\n",
      "Iteration 41, loss = 0.00880352\n",
      "Iteration 42, loss = 0.00808085\n",
      "Iteration 43, loss = 0.00773290\n",
      "Iteration 44, loss = 0.00722441\n",
      "Iteration 45, loss = 0.00660096\n",
      "Iteration 46, loss = 0.00627230\n",
      "Iteration 47, loss = 0.00596447\n",
      "Iteration 48, loss = 0.00532579\n",
      "Iteration 49, loss = 0.00497175\n",
      "Iteration 50, loss = 0.00459682\n",
      "Iteration 51, loss = 0.00435803\n",
      "Iteration 52, loss = 0.00420560\n",
      "Iteration 53, loss = 0.00405542\n",
      "Iteration 54, loss = 0.00345795\n",
      "Iteration 55, loss = 0.00334912\n",
      "Iteration 56, loss = 0.00313512\n",
      "Iteration 57, loss = 0.00308484\n",
      "Iteration 58, loss = 0.00275003\n",
      "Iteration 59, loss = 0.00251521\n",
      "Iteration 60, loss = 0.00238354\n",
      "Iteration 61, loss = 0.00228217\n",
      "Iteration 62, loss = 0.00218697\n",
      "Iteration 63, loss = 0.00211407\n",
      "Iteration 64, loss = 0.00213615\n",
      "Iteration 65, loss = 0.00214779\n",
      "Iteration 66, loss = 0.00182929\n",
      "Iteration 67, loss = 0.00153965\n",
      "Iteration 68, loss = 0.00147874\n",
      "Iteration 69, loss = 0.00139277\n",
      "Iteration 70, loss = 0.00136678\n",
      "Iteration 71, loss = 0.00134102\n",
      "Iteration 72, loss = 0.00121544\n",
      "Iteration 73, loss = 0.00114590\n",
      "Iteration 74, loss = 0.00108203\n",
      "Iteration 75, loss = 0.00105749\n",
      "Iteration 76, loss = 0.00214668\n",
      "Iteration 77, loss = 0.00755201\n",
      "Iteration 78, loss = 0.00350651\n",
      "Iteration 79, loss = 0.00151964\n",
      "Iteration 80, loss = 0.00104490\n",
      "Iteration 81, loss = 0.00086642\n",
      "Iteration 82, loss = 0.00082054\n",
      "Iteration 83, loss = 0.00077348\n",
      "Iteration 84, loss = 0.00074681\n",
      "Iteration 85, loss = 0.00072460\n",
      "Iteration 86, loss = 0.00070362\n",
      "Iteration 87, loss = 0.00068919\n",
      "Iteration 88, loss = 0.00066509\n",
      "Iteration 89, loss = 0.00064858\n",
      "Iteration 90, loss = 0.00064512\n",
      "Iteration 91, loss = 0.00061836\n",
      "Iteration 92, loss = 0.00061250\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "[[ 971    0    5    0    2    3    6    0    3    2]\n",
      " [   1 1125    1    0    0    1    2    4    0    4]\n",
      " [   1    4 1008    4    2    0    3    8    2    0]\n",
      " [   0    0    1  988    0   10    2    3    7    3]\n",
      " [   2    0    2    0  959    2    2    3    2    7]\n",
      " [   0    0    0    4    0  865    7    0    2    2]\n",
      " [   3    2    4    0    4    3  934    0    0    0]\n",
      " [   1    1    5    2    3    2    1 1000    5    5]\n",
      " [   1    3    5    7    3    5    1    5  948    4]\n",
      " [   0    0    1    5    9    1    0    5    5  982]]\n",
      "테스트 집합에 대한 정확률은 97.8 %입니다.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# MNIST 데이터셋을 읽고 훈련 집합과 테스트 집합으로 분할\n",
    "mnist=fetch_openml('mnist_784')\n",
    "mnist.data=mnist.data/255.0\n",
    "x_train=mnist.data[:60000]; x_test=mnist.data[60000:]\n",
    "y_train=np.int16(mnist.target[:60000]); y_test=np.int16(mnist.target[60000:])\n",
    "\n",
    "# MLP 분류기 모델을 학습\n",
    "mlp=MLPClassifier(hidden_layer_sizes=(100), learning_rate_init=0.001,batch_size=512,max_iter=300,solver='adam',verbose=True)\n",
    "mlp.fit(x_train,y_train)\n",
    "\n",
    "# 테스트 집합으로 예측\n",
    "res=mlp.predict(x_test)\n",
    "\n",
    "# 혼동 행렬\n",
    "conf=np.zeros((10,10),dtype=np.int16)\n",
    "for i in range(len(res)):\n",
    "  conf[res[i]][y_test[i]]+=1\n",
    "print(conf)\n",
    "\n",
    "# 정확률 계산\n",
    "no_correct=0\n",
    "for i in range(10):\n",
    "  no_correct+=conf[i][i]\n",
    "accuracy=no_correct/len(res)\n",
    "print(\"테스트 집합에 대한 정확률은\", accuracy*100,\"%입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b47680",
   "metadata": {},
   "source": [
    "## 프로그램 4-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c2add6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하이퍼 매개변수 최적화에 걸린 시간은 143.45839715003967 초입니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA/pElEQVR4nO3dd3hc5ZX48e9Rty3ZMu4NW6baJmCMMNgQEBAMhE5CqKEkBMimQQohpEHYTViSzY8SNizJGkJvIUAIrB0IwoE4gAG54YJbbLlbRrZlWf38/jj3orF8JY3KaDTS+TzPPJq5bd53ZvSe+5b7XlFVnHPOuabSkp0A55xz3ZMHCOecc5E8QDjnnIvkAcI551wkDxDOOecieYBwzjkXyQOE61IioiJyYPD8fhH5cTzbtuN9LhOR2e1NZ08nIhUiMr6F9WtE5DNdmSbX/XiAcG0iIrNE5GcRy88VkU0ikhHvsVT1elW9vRPSNC4IJp+8t6o+pqozOnrsZt6vv4jcJSJrg4J2RfB6cCLeLxFUNVdVVwGIyEMi8u/tPZaIXBV8/r9usvy8YPlDwet9vqeYbW8Vkdrg8ywXkX+IyLT2psl1Dg8Qrq0eAr4oItJk+ReBx1S1ruuT1HVEJAt4DZgEnA70B6YDZcDUdhwv7oDaza0ELmqSnyuA5W04xlOqmgsMAd4Enov4nbku5AHCtdXzwH7Ap8MFIjIQOAt4WESmisjc4Cxwo4j8JihU99H0zFVEvhfss0FEvtRk2zNF5AMR2Ski60Tk1pjVc4K/5cEZ6LTgrPbNmP2ni8i7IrIj+Ds9Zl2xiNwuIm+JyC4Rmd1CbeAKYH/gfFX9UFUbVHWLqt6uqi8Hx9uraSw2nyJSJCKlIvJ9EdkEPCgiS0TkrJjtM0Rkm4hMCV4fG5xRl4vIfBEpaubzvFpE/hzzeoWIPB3zep2ITI5No4hcC1wG3BR8dn+OOeRkEVkQfGZPiUhOM58JwCZgIXBacPz9sMD5Ygv7RFLVWuAPwHBgUFv3d53HA4RrE1XdAzyNFZShLwBLVXU+UA/cCAwGpgGnAP/W2nFF5HTgu8CpwEFA0/bv3cF75gNnAl8VkfOCdScEf/ODppO5TY69H/AX4B6swPk18BcRiS18LgWuBoYCWUFaonwG+D9VrWgtTy0YjgXZscC1wBPAJTHrTwO2qer7IjIqSPu/B/t8F/ijiAyJOO4bwKdFJE1ERgCZwHEAQX9DLrAgdgdVfQB4DLgz+OzOjln9BayWVAAcDlzVSr4epvF3cTHwAlDdyj77EJHs4L1KVXVbW/d3nccDhGuPPwAXikif4PUVwTJU9T1V/aeq1qnqGuB/gBPjOOYXgAdVdZGq7gZujV2pqsWqujA4Y1+AFarxHBcsoHykqo8E6XoCWArEFoYPqurymAA4uZljDQI2xvm+zWkAfqqq1cH7PQ6cIyJ9g/WXBssALgdeVtWXg7z/FZgHfLbpQYM+hV1B2k8EZgHrReTQ4PXfVbWhDem8R1U3qOp24M80/5mE/gQUicgA7DfxcBveC+ALIlIOrAOOAs5r4/6uk3mAcG2mqm8CW4FzgzPTowkKNBE5WEReCjqsdwI/x2oTrRmJFQyhf8WuFJFjROR1EdkqIjuA6+M8bnjsfzVZ9i9gVMzrTTHPK7Gz7ShlwIg437c5W1W1KnyhqiuAJcDZQZA4h8YAMRYLxuXhAzi+hTS8ARRhtao3gGIsOJwYvG6LeD+TMB97sNrOj4DBqvpWG9/vaVXNV9Whqnqyqr7Xxv1dJ/MA4dorbE74IjBbVTcHy3+LnZ0fpKr9gVuAeDoaNwJjYl7v32T941h79hhVHQDcH3Pc1qYk3oAVtLH2B9bHka6mXgVOE5F+LWxTCfSNeT28yfqo9IbNTOcCHwZBAyxoPhIUnOGjn6re0cx7hwHi08HzN2g9QHTmlM4PA98BHunEY7ok8QDh2uthrD3+KwTNS4E8YCdQETRtfDXO4z0NXCUiE4Oz6J82WZ8HbFfVKhGZijXDhLZizTbNjet/GThYRC4NOoAvAiYCL8WZtliPYIX2H0Xk0KC9f5CI3CIiYbNPCXCpiKQHfSvxNIU9CczAPq/HY5Y/itUsTguOlxN0dI9u5jhvACcBfVS1FPg71o8wCPigmX020/xn11ZvYP1I97awTXaQj/Dh5VA35V+Ma5egf+EfQD/2HqnyXazw3gX8DngqzuO9AtwF/A1YEfyN9W/Az0RkF/ATLKCE+1YC/wG8FTTDHNvk2GXYKKvvYE1ENwFntacDVFWrscC4FPgrFgzfwZq73g42+xbWv1GOjRB6Po7jbgTmYiN/nopZvg6rVdyCBcJ1wPdo5n9XVZcDFVhgQFV3AquAt1S1vpm3/19gYvDZtZrWVvKhqvpa0G/RnApgT8zj5I68p0sc8RsGOeeci+I1COecc5E8QDjnnIvkAcI551wkDxDOOeci9ZSJwgAYPHiwjhs3LtnJSIrdu3fTr19LQ/N7Ns+/59/z3778v/fee9tUNWrqlp4VIMaNG8e8efOSnYykKC4upqioKNnJSBrPv+ff81/Urn1FpOksA5/wJibnnHORPEA455yL5AHCOedcJA8QzjnnInmAcM45F8kDhHPOuUgeIJxzzkXyAOGccy6SBwjnnHORPEA455yL5AHCOedcJA8QzjnnInmAcM45F8kDhHPOuUgeIJxzzkVKWIAQkZkiskVEFjWzXkTkHhFZISILRGRKzLrTRWRZsO7mRKXROedc8xJZg3gIOL2F9WcABwWPa4HfAohIOnBfsH4icImITExgOp1zzkVI2B3lVHWOiIxrYZNzgYdVVYF/iki+iIwAxgErVHUVgIg8GWz7YaLSyg03QElJwg7fFSaXl0N+frKTkTSe/3LPfy/O/4GDB0MC7qiXzFuOjgLWxbwuDZZFLT+muYOIyLVYDYRhw4ZRXFzc5oQcWFpK7vbtbd6vO6lXpTzF89ARnn/Pf2/Of03//u0q+1qTzAAhEcu0heWRVPUB4AGAwsJCbdd9WXvAvWz9nryef89/UbKTkTQlCcp/MgNEKTAm5vVoYAOQ1cxy55xzXSiZw1xfBK4IRjMdC+xQ1Y3Au8BBIlIgIlnAxcG2zjnnulDCahAi8gRQBAwWkVLgp0AmgKreD7wMfBZYAVQCVwfr6kTk68AsIB2YqaqLE5VO55xz0RI5iumSVtYr8LVm1r2MBRDnnHNJ4ldSO+eci+QBwjnnXCQPEM455yJ5gHDOORfJA4RzzrlIHiCcc85F8gDhnHMukgcI55xzkTxAOOeci+QBwjnnXCQPEM455yJ5gHDOJV1DQ7JT4KIk834QzjlHeTm89x6oQv/+jY8+fSAnB7KzIc1PZZPCA4RzLmm2bYN58yAvDzIzoaYG1q+HNWsatxGBfv1smwED7HlOjj0yM5OW9F7BA4RzKa6uDmprYccOO/OWqJv2dkObNsEHH1ihn51ty/r0sUcsVctfeTls3rx3c1RWluW5utrW9+/vtY3O5AHCuRRWWWmF7J498I9/WEE7ZgwMG2Zn3N01WJSWwoIFsN9+rdcCRCwQZGVBbu7e6+rqLO81NTB3rm0zejQMH55awbK78gDhXIravt3a7jMy7DF0qJ1pr14NK1ZYE8z++9vy3NzuUViqWvqWLIHBgy3dHRHmfdcuy2ddHaxdC6tWWf7HjLHl3TlYdmceIJxLMapWCC5ebM0zOTl2Fg12Nj5okD2vrYWVK2H5cujb14LFkCH7noV3ZbqXL7fgNWQIpKd3/ntkZFitBCz/q1bBRx9Zs1Vs/j1YxMcDhOs1VKG+3s4ym/5taLDmmfCRiMKrM9TV2dn3unUWCFo6A48NFjU1VjgvXWqdvGFh2a9f16S7ocHS/a9/2Rl9V/QTNM3/ihWwbFly8p+qPEC4lNfQYAX9pk1WENTUWKdl+Le21v7W11uQiEefPtYs0b+/nXGGwy2TOeQy7G/YvdsK2bacBWdlWZMO2GexbJkV2Hl5VlgOHmy1jESor4eFC2HDhranu7NkZTUGi+by36eP1yya8gDhUtquXbBokRWaJSX2D56RYYV4ero9MjPbXiuorYWKCvj4Y3seErGCNDe3cchldrYVLuFInESI7W8IC7r2CgMdQFWVFZQNDVZ4FxTAwIGdV1DW1sL8+VBWZh3n3UFz+U9PtxOCAQPsEY6oys7uvYHDA4TrMFVr+ujKMen19TZWPmxfz8iwJoPOkpkZnZ9wyOXOnVbo1dU1rhsyBMaOtTbwzqplqFqzzIcfNvY3dKbwegJVC7Zvv21B78ADLT8d+U6rq+H99+24Ye2luwnzDxYkampg40b7zENpab03cHiAcO2iamfYW7dae/iePVZVHzcucU0VofJyGyJZWWln0+npVoPoCrFDLmOFn8e779q6ggIbatmRzyLsb1i7NnGduiERa27Jy7Oz6vnz7f0KCmDUqLbnY88euwCupqbjNZ6ukpa2d8AIxRM4+ve3YBrWXGP/Nn2eSkHFA4SLW9OgUFlpP/y8PCtANmywf6Bx4+zR9IKnjqqttY7G1avtPTuzxtBRItbslJtrBftHH1k7d2ytoi0FfNjfUFFhTTNdWaiEhWRdXeOQ2eHD7TvNz289LWGgVLXtU108gWPt2r37t0T27e8Kl6WnW403M7NxmG5GRse+46oqq1V39kmEB4huoKzMCteCguQNQWxOS0GhaVoHDrR/mtLSvQNFZzSLbNtmHZ21tVboduerZTMyGptUKirsTDoz0wLFyJGtj5wpK7OmmdjjJEPY36FqtbZ//tO+9wMOsO8gagTVzp3wzjuW3+72W+5szQWO1jQ0ND7q6+033dHJCmtq7DgeIHqQ8Exz9Wr7hyottX++goLkzjHTlqDQVFqanS03NNhZ1Zo1lp+xY9sXKMIRJ+vW2dlo//7tyVHyxNYqwrPxQYMscIbNY6FE9ze0l0jjBHpVVTYYICOjsfkprCl+/LEFh759E9/MmMrCpqbOtGNH5x4v5AEiSXbssHbePXsah/41NFiBum4dTJxo1fqualpQtXb8rVutYG9LUIiSlmYFYH29FXqrV1vw23//+Eb7qNq8OwsX2uuubmbpbLGjj3bvbhyRFNYqsrOtv6G01GoN3fU6jNjmp/AitJEjLW8LF1oQ6S6BzXWcB4gu1tBgheWyZVbwxjYhhIVqTY2dpeXnW6AYMCBx6amuhi1bLE27d3csKERJT28MFKtXW6EyfnzLgWLPHjuL3rTJaiNNO4RTXb9+9qirs+C5cqV9TqrJu06grWKbn7ZvtxlYBw7sed9Vb+cBogvt3m2jb8rLWz5LzMqygqKiwiZgGzvWzr47a5x92KZcWmr/2OEIlqFDO+f4UZoGirBGMWZMY6HS0GDp+fBDK4CGD09cerqD2Gkh6uo6Pi9RMsQ2P7meJwV/kqlH1Qq+xYutkI+3IM7NtTPN9evtceih1ubb3vbLsLawapU1IWVnW6HdlR2+YaCoq7Mz55UrLVAMGmS1qu3brdBMxcKyI3pbfl1q8J9lglVVWWDYvLn1uXOiiFiBWVdnVwyvWQOTJjWeebYmGbWFeIRNFHV11nG7fLl1diY7Xc65RgkNECJyOnA3kA78XlXvaLJ+IDATOACoAr6kqouCdTcC1wAKLASuVtWqRKa3s23ebE1KaWkdn2YgnM65stKGG44cCQcf3Pxoke5QW4hHsodyOueal7AAISLpwH3AqUAp8K6IvKiqH8ZsdgtQoqrni8ihwfaniMgo4JvARFXdIyJPAxcDDyUqvZ2ppsaaS9au7fxO1r597Uy7rAzmzLEgsf/+tq671hacc6kpkTWIqcAKVV0FICJPAucCsQFiIvALAFVdKiLjRCQ8184A+ohILdAX2JDAtHaa7dtt+GptbeKGZorYCKf6emua+de/7P3+/nfrCO+utQXnXGpJZIAYBayLeV0KHNNkm/nABcCbIjIVGAuMVtX3RORXwFpgDzBbVWdHvYmIXAtcCzBs2DCKi4s7NRNtUV1tj/R0K8S3bOma962shLq6CmprixGxfo+qlGqM67i6ugo2by5OdjKSxvPfu/OvWsHcucWdfkKayAARldSms/HfAdwtIiVYP8MHQF3QN3EuUACUA8+IyOWq+ug+B1R9AHgAoLCwUIuKijor/Xupq2t81NY2Pq+utnH7W7daE8+IEck5c9+8uZhhw4q6/o27Cc+/578353/9+mKmTSvq9IsUExkgSoExMa9H06SZSFV3AlcDiIgAq4PHacBqVd0arHsOmA7sEyA6Q0ODtenX1tqZd1joh89rasL07rtveM+B7OzuNXmcc851VCIDxLvAQSJSAKzHOpkvjd1ARPKBSlWtwUYszVHVnSKyFjhWRPpiTUynAPMSldA9e2wOmXCWxbDQT0+3TmG/4blzrjdKWIBQ1ToR+TowCxvmOlNVF4vI9cH6+4EJwMMiUo91Xn85WPe2iDwLvA/UYU1PDyQqrWDBwGsAzjnXKKHXQajqy8DLTZbdH/N8LnBQM/v+FPhpItPnnHOueT4Q0jnnXCQPEM455yJ5gHDOORfJA4RzzrlIHiCcc0m1bZvNVBxeb+S6D5/u2zmXFKrw/PPw61/btUiZmTBhAhxxhD0OPzz+ae1dYniAcCltzx546y3YsGE4Bx9sEyQOG9b8NOiue9i2DW6/3b67qVPh/PPtToLz58OTT8Ijj9h2Y8Y0BosjjoCCAp+Esit5gHApp7oa5s6FWbNsBlubmPDQvbbJy2sMFrGP4cPt79ChnXcLV9c2r74Kv/iFfW/f/S584QtW6J96qq2vroYlS+xeKvPnWxB56SVbl5cHn/qUBYzJk+3mWX36JC0rPZ4HCJcS6urg7bdh9mwoLrZpzfPz4cwzrWDJzPwn9fXHsnkznzw2bbK/ixbBjh37HnPgwMbAMXEizJhhZ6zdWX29nX3H5nPzZqisPJCCAgt8YZ4GD+5etzLduRPuvBP+7//s8/7Zz2DcuH23y862wn/yZHutavc4mT+/8fGPf9i69HS7J8qECeM57zxrovJpcTpPN/r5OLe3+np4/30LCn/7mxXyublw8slWmB99dGMBuHlzVYt37auq2rdQDR9r18Ibb8Bvf9sYKD7zGattdKWGBvj4433TFwa6zZstONTX771fnz6gOmKfKd7T0ixIxNagwgAyfLg9HzTICtlE++c/LSCUlcH118NVV8UfvEQscI8ZA2edZct27oSFCxtrGS++OJrnnoPRo+37mzEDDjwwYdnpNUSjpihNUYWFhTpvXtvn9Nu925oqUnkupp4y3XFDg/3T//Wv1hRRVmYF4IknWk1h2rToO/R1NP+bNtn7zZ5tbeFgZ7AzZsApp1hB2pmqqqxmM3++5XfNGrt/SG3t3ttlZUU3lcU2l+XmWv779SvaJ7hs2bJ3kKmu3vv44RxkBx9seT3hhM7tv9mzB+65B555xvoPfvYzO8vvbCtWvMmiRcczezbMm2e/o/HjG4NFeNfF7qSuziYJnT0bVq7cd31rNaHY9Tk5Zbz55qB2TfctIu+pamHkOg8QHiCSTRWWLrV/lNmzrSDLyoLjj7d/7uOPp9Uffmfmf926xrSsXGln4oWFlpaTToIBA9p+zK1b924iWbassSYwfjwcdFB04Z+fH1+TSTz5V7Uz76gaynvvWTDJzrYgMWMGTJ/esX6aBQvgpz+15qFLL4WvfrX177G9YvNfVgavvWbfX0mJrZ8wwfJ06qldXzOMVV8PH3xg/WexteLDD9+7871psdxaMZ2evpnZs4d5gGiJB4iiZCcjUl2dFZBNm0tiC6jycmtyOPbYxjPZ3Nz43yNR+V+xwmozs2db4MjIsFpMmMZ+/fbdp77eAksYDBYsgA3BnVCys61jNXYoZ//+HU9nR/Pf0GBpnT3balIff2x5O+kky+vUqfE3CdXWwgMPwB/+YM1Yt95qATaRmst/VM3wiCMamxE7u2YYpaHBmsPCzzasFYeBuLlacVusX1/MjBntu2GQB4hWeIDomIoKayKJKvzDdvOmP7Pc3L3PmCdNav/ZOSQ+/1G1nOzsxlpObm5jMFi40H5TYH0AYTA44gg45JDEdBx3Zv7r6qyZZtYseP11+37z862pbcYMOPLI5oearlgBP/mJ3Sv97LPhO99pW6Bvr3jy31LNcNo0+//vrCG0qlZLnDXLTjA2bbIgcNxxcNpp8dWK28IDRBw8QBR16XuWlsJjj8GLL+7dtp2TE91cEvuIOvPuiK7Mf9hPEp4Rbt9uy0WsYzQ2IIwY0TWjahKV/5oaGzE0ezbMmWN9J0OGWFPNjBkW2EWs1vT44/Df/21DUX/4Q+s36iptzf/KlVZwz5plgQOsP6al3+3w4Vbba+n7XLmyMQitW2fHnDbNPq8TT0xcsExUgPBRTK7NPvzQLmR67TU74zrjDDv7D/+hWvsnSnVpaY3DML/9bWvnrquDww7rmrPlrpSVBUVF9tizx06kZs2yTufHH4dRo6zwmz/f2tZPOgluucWGEHdnBxxgj+uus5rhokV7N3mGAyWajhgLT36aBo9t22z72JrJlVd2rFbcHXiAcHFRtTPJRx6x5od+/eCLX4SLL07tmldHZWQkvn29u+jTp3FU0K5ddj3K7Nn2m8jJsb6GM89MrZMDEevAjhpZ1dBgtcNNm/ZtPt20yYJBWVlj8+nkyXDTTYkZ9ZYsHiBci2pr7Yzx0UetfXnoULjhBjjvvJ53tuzil5dnfQxnn904wKCn/R7C60gGD7baYZTaWhuAkZVl2/U0HiBcpN274U9/gieesDOm8ePtDPG002xSNedC+fnJTkHyZGbCyJHJTkXieIDooOpqeO45+yc59dTuNbVBe2zbZpOlPfusjV456ij4wQ9s9EUqNR045zouxYuz5Fq61Ib0rVplr3/zG7jkktRsflmzxtqSX37ZOuZOPtn6GCZNSnbKnHPJ4gGiHerq4KGH4He/s/nq777bOqoefRTuusuWX3ABXHRRYq/aLC+3kUR/+xts2VJIRsa+Z/kijcua/g2f19XZmO3sbAtul11mc9o453o3DxBttGaN1Ro+/BBOP91GLYRXwh5/vE1T/MgjNgTw8cdtxMcXv2hz3XSGcPTIX/9qs5vW19s8M6NG7SEry6ot4aiK2Etcmi5ruu4rX7Fpl7v78ETnXNdpNUCIyFnAy6ra0AXp6bYaGuCpp6wZKScH7rjDLtVvasIE+PnPbWqFJ56wO2a98gocc4wFimOOaXtb/p49dpHS7Nk21LS21jrGLr/cAtDBB8OWLYu77VQbzrnUFE8N4mLgbhH5I/Cgqi5JcJq6nY0b4bbbbPz/8cfDj37U+pC2kSNtmoGvfMU6sZ98Er7+dbvS9vLLWx8NVF3deAVreFOcIUPg85+3fcMrWJ1zLlFaDRCqermI9AcuAR4UEQUeBJ5Q1V2JTmAyqdqdrH71K3v+ox/Buee2rWDu39/mvr/0Urue4JFHbLjofffZRWYXXGBjysH6Av75T2s+ir0pzllnWU1h8mS/3aJzruvE1QehqjuDGkQf4AbgfOB7InKPqt6bwPQlTVkZ/Md/WNPOlCk2bfGoUe0/XlaWXVR01ll2u8xHH4V774WZM+Gcc6yGEE7/m5fXODFaYWHqD511zqWmePogzga+BBwAPAJMVdUtItIXWAL0uADxt79ZP0JlpV01fOmlnXfmLmLz7E+fbsNkH30Unn66cc6bU0+1Ka87Ov2vc851VDznphcC/09V58QuVNVKEflSYpKVHLt2wS9/adcCHHqo3f1q/PjEvd+hh8K//zt873s2xDRRN1Nxzrn2iCdA/BTYGL4QkT7AMFVdo6qvJSxlXez99+3WiNu2Wcfyl7/cdU07qTzbo3Ou54qn4eQZIHaIa32wrFUicrqILBORFSJyc8T6gSLyJxFZICLviMhhMevyReRZEVkqIktEZFo879lWe/bYaKMf/tBmq5w506YA9nZ/51xvF0+AyFDVmvBF8LzVFnIRSQfuA84AJgKXiMjEJpvdApSo6uHAFcDdMevuBv5PVQ8FjsD6OxLijTfsCuJHH/WpJZxzLhRPgNgqIueEL0TkXGBbHPtNBVao6qogqDwJnNtkm4nAawCquhQYJyLDgmG1JwD/G6yrUdXyON6zzfr0sesMrrvO+wCccy5WPA0p1wOPichvAAHWYWf7rRkVbBsqBY5pss184ALgTRGZCowFRmPNWFux6y6OAN4DvqWqu5u+iYhcC1wLMGzYMIqLi+NI2t4aGuzWips3t3nXbqOuroLNm4uTnYyk8fx7/ntz/lUrmDu3uNMvno3nQrmVwLEikovdwzrei+Oiktr0Bth3YFdplwALgQ+AOiATmAJ8Q1XfFpG7gZuBH0ek7wHgAbB7UhcVFcWZvEZ+T+rUl+r5r6rqWA021fPfUb09/+vXFzNtWvvuSd2SuLpiReRMYBKQI0GIUtWftbJbKTAm5vVoYEPsBqq6E7g6eA8BVgePvkCpqr4dbPosFiBcD6Rq956or7fnDQ32aEl4phROOlhXZ3f2ysy0qdZTZZCBqqU7O9sukuzf35o9nesO4rlQ7n6swD4J+D3weeCdOI79LnCQiBQA67E5nS5tcux8oDLoo7gGmBMEjZ0isk5EDlHVZcApwIdx58qljNpau+/v8OGNBXv4SEuzR3p64/PmHn//Oxx+uBW2GzbYXFZpadC3r52Zd8d5q+rrLb0FBXDIITZ9++LF1tQ5aFDqBDnXc8XzE5yuqoeLyAJVvU1E/gt4rrWdVLVORL4OzALSgZmqulhErg/W3w9MAB4WkXosAHw55hDfwPo+soBVBDUN13Ps2mUF+ZQpnXPfjP32s8fBB1uz4ccfW7DYFgypyM6Gfv0s4CRbTY0FxkmTYOxYC2CDBtlkkOvX21X2qjb9us+/5ZIlngBRFfytFJGRQBlQEM/BVfVl4OUmy+6PeT4XOKiZfUuAwnjex6WWhgab62rAADj6aCu0O5OI1UZyc2HMGCuMd+ywM/NNm6zWkp5u67OzO/e947FnjwXHwkIYNmzvdWlpluZhw+xOhatXWxr9YsqeraLCmklbkoxacDwB4s9BU9AvgfexjubfJTJRrueqrramlAMOsKnPu+JsPivLBiAMGQITJ1rhXFZmtYstW+wfr2/fzg9UUXbutAA5fXrLhX5Wlk3FMnq01SY2bbLte1r/RHW1fSZhX1IyA3cy1Nfbb3HQIJu5ORR1s6/mqMLatS3fPqC9WgwQIpIGvBZcg/BHEXkJyFHVHZ2fFNfTlZfbj3nq1Nbvp5EoaWlW0A4YYPNs7dlj6Vq3zmoYeXkWLBJh+3Y79pQp8Rf0ublw1FG27+LFFtD22y/1+yd277ZHTg4cdhgMHWrfRVkZlJZajS8tzT6nvn27Zx9SR+3ZY8Fx4kS7K2RHmhI3b07MyVaLPzNVbQj6HKYFr6uB6s5PhuvJwrOkIUOsMOhOFyT26WOP4cOtEF661ArhAQM67yxW1Y45bJh1pLf1TC/snzjuOKv1pGr/hKoViFVVlvbCQstXmIesrMbAXVlpgXv9eutDUrXvIze3e/QhddT27Rbkp0/fu+bQ3cRzHjJbRD4HPKfaWmXHub2FZ0mHHgrjxnXfAi0shKdNs8J8yRI7i+3o2Xo4Umn8eBup1JH8p6db/8TQodY3sXq1BdvwnugtaWiwvpfaWmvrrqvbt+lC1dLXr1/njvyqr7fPsq7O7rQ4blzrfSp9+9pj5EhL844d1sy2caMdJz3danupNi1+XZ2dLI0aZbcn7u7pj+en/22gH1AnIlXYBXCqqnH8LF1vlipnSbHS0qw2MWSINXUsX26F68CBbT9zramxkVSHHWZNCJ1V4GZnW8AdNQqWLbPmhYYGO+sOg0DTwj8jwwrc/Hz7m5trhVNmpv3NyLAmn/JyK4jLyuyY6emNAaOtwoJdxEZqjRnTvua7zExrkhw82Jpjdu60WsX69ZbetLTWr5vpDioq7ITp8MPtu0uFZrN4rqTO64qEuJ4jPEsaOdL+obv7WVKU9HQr1EaMgH/9C1autEI0Pz++f+zKSitwCwvtjD8R8vKsf6KsDN5+25rKBg9uLNCzshof8dSCwr6ZsWPtO9y1ywLcxo1WC1K1wrpv35ab38JRWmEgGzGi834DaWn2HeTn2yCHcDjz/PlW8wtrQN2pM1/VvqN+/ayZMC+FStR4LpQ7IWp50xsI9Wa7dtlj+PDu24TSVSoqrHBMpbOklmRlwUEH2WiiVatstEhrw053BEM4pk+Pr/mnI0Qag0JhJw4Kz8iwWtPAgdY8VlPTOPpr82YLGGABo18/+7trl333/fvDkUdaLSzR/QX9+tljxQq7E+O2bRbQt2zpWO2ns4S1yHHj7PqcVBtcEE9yvxfzPAebpfU94OSEpCjF1NTYY+xYq5oPGpTsFCVHeJbUt69d7JVKZ0nx6NPHLmrbf3/46CP7rvv1s6aaWOGZYltGKqWCrCz7bQ8aZAVdODx12zb7LD7+2GpKRxwRfy2rs+XkWCAfPdoC1datFtDDYNHVfRZhv8tRR+17vUuqiKeJ6ezY1yIyBrgzYSlKIQ0N1s5+9NF2prVtm/3j9JYx3KGqKmsLLihIzbOktsjLs8L/44+tI3vz5sYRT1u3WiHZnpFKqSY7u/HakgkT7CSpOzUl9u1rJ21jx1qtdssWq1mUl9vvs3//xP1OGxqsLBg40H4LiRo23RXa8xGVAoe1ulUvsG2bNT+EbcyTJsG8eZ0zbUQqqK+3AJmdbUEyUW3t3dHAgTbiaetWCxTl5Z0zUilVdafg0FR4VX1BgTWDbd5s171UV1u6O3Nyx6oqqzkcdJD9HlJ9SG48fRD30jhNdxowGbuPQ69WXm5nTwce2Lhs6FDrkPv449QZtdMeqvZPUFtrNYb99+/ZtYbmiNh3PmiQnaX6dBjdm4jVHPr3tyv5d+60Dvj16+23HDaLiVjBHk4S2fRvcycA5eX295hjek5Tczz/1vNintcBT6jqWwlKT0rYs8d+RJ/61N4/FhEbtTFnjrU9dlWhWVNj71dRYe3fiWz/ray0s7CRIy04pHL1ubOkp3twSDWxo6EOOcSCRW2t1Ypra612UVvb2MdYW9s4jDhqSK2qnSxMmtS9LgTtqHiKsGeBKlWtB7vXtIj0VdXKxCatewqH/02bFt3X0Levtcl++GHXNLmE/SA5OVZVDof65ed3boCqrbWaUV6ejRbZb7/OO7ZzyRT+v8SrocECSeyjocFOElJ91F5T8RQhrwGfASqC132A2cD0RCWquwpH6hx2WMs/qDFj7CKr3bsTPwFc2A+yYYONlqistGrz6tVWqIfDANurocECQ1hjGjmyd7axOxcKm5l6+kAEiC9A5KhqGBxQ1QoR6ZUNC9u3W+E/ZkzL26WlWRB56y0b6pioAjW2H2RDcK++vn2tfXXcOEvv6tVWq2jPyI1du6w5bexYO2ZvG53lXG8XT3GxW0SmqOr7ACJyFLAnscnqfioqrPA99ND4qpEDBtioiXXrEtNhVVlpgadpP0goPb1xGOLu3RZA1qyxJrLc3Jb7DsIpuQcNsiGdib7YyznXPcUTIG4AnhGR8H7SI4CLEpaibqimxoavHXdc26qV4Zl9Z18bEfaDHHdcfMft18+aoQoKrIkstlYxYEDjULz6emtOysy05qqhQ3tem6pzLn7xXCj3rogcChyCTdS3VFVrE56ybiLsBC4s3Peq2dZkZlpTU2deG6Fq/Q5HHNH2kTMZGXZF57BhFmA2bLCLh+rrbV19vQWSsWN757BV59ze4rkO4mvAY6q6KHg9UEQuUdX/TnjquoFt26wm0N5L5YcOteBQXt4510Zs22Y1gdGjO3acvDwb3nfAAXaxV3m5BQYftuqcC8XTffqV4I5yAKjqx8BXEpaibiRshz8o8q7Z8RGxYa/hPPwdsWOH1RoOOaRjx4mVkWEX902Y4MHBObe3eAJEmkhjS7SIpAPd+ML6zlFVZX8PP7zjo5DCayO2b+9YeurrYfLk1L983zmXGuIp+mYBT4vIKSJyMvAE8Epik5VcdXV2tj5lSuddFTlmjI0G2r277fvW11tt5qijetYMoc657i2eAPF97GK5rwJfAxZgF8v1WGVldsn8wIGdd8y0NDtmRUXb7361bZvt61cvO+e6UqsBQlUbgH8Cq4BC4BRgSYLTlTTh/WL337/zj52fbxewffxx29IzcqR1IDvnXFdqdhSTiBwMXAxcApQBTwGo6kldk7SuV1FhTUoTJyZu/P+BB9pUGPFcGxGmZ9Ikvx7BOdf1WqpBLMVqC2er6vGqei9Q3zXJ6nr19dYRPGVKYudYycqyayPCqYGbU1Nj01wkOj3OOdeclgLE54BNwOsi8jsROQW7UK5Hysiwi8/aejFcewwdatdVNBckwgnyjjyya9LjnHNRmg0QqvonVb0IOBQoBm4EhonIb0VkRhelr0vk5Fhw6Ko7wbV2bURHL85zzrnOEE8n9W5VfUxVzwJGAyXAzYlOWFdKT+/624SGE/81vTYi6k51zjmXDG26BExVt6vq/6jqyYlKUG8yZoxNeRFeG7FnT8sztDrnXFfyYiiJ0tOtw7qiwpqbdu2yTmm/74JzrjtIaIAQkdNFZJmIrBCRfZqlgon//iQiC0TkHRE5rMn6dBH5QEReSmQ6kym8NmLjRqs5+L2NnXPdRcICRDBn033AGcBE4BIRmdhks1uAElU9HLgCuLvJ+m/Rgy/KCx14IBx9tF2g55xz3UUiaxBTgRWqukpVa4AngXObbDMRm8YDVV0KjBORYQAiMho4E/h9AtPYLWRl2fTdfjGcc647SeRtYUYB62JelwLHNNlmPnAB8KaITAXGYiOlNgN3ATcBeS29iYhcC1wLMGzYMIqLizsh6amnoqKi1+YdPP+ef89/IvKfyAARdT6sTV7fAdwtIiXAQuADoE5EzgK2qOp7IlLU0puo6gPAAwCFhYVaVNTi5j1WcXExvTXv4Pn3/Hv+E5H/RAaIUmBMzOvRwIbYDVR1J3A1QHDPidXB42LgHBH5LJAD9BeRR1X18gSm1znnXIxE9kG8CxwkIgUikoUV+i/GbiAi+cE6gGuAOaq6U1V/oKqjVXVcsN/fPDg451zXSlgNQlXrROTr2A2H0oGZqrpYRK4P1t8PTAAeFpF64EPgy4lKj3POubZJZBMTqvoy8HKTZffHPJ8LtHjHZ1UtxuaCcs4514X8SmrnnHORPEA455yL5AHCOedcJA8QzjnnInmAcM45F8kDhHPOuUgeIJxzzkXyAOGccy6SBwjnnHORPEA455yL5AHCOedcJA8QzjnnInmAcM45F8kDhHPOuUgeIJxzzkXyAOGccy6SBwjnnHORPEA455yL5AHCOedcJA8QzjnnInmAcM45F8kDhHPOuUgeIJxzzkXyAOGccy6SBwjnnHORPEA455yL5AHCOedcJA8QzjnnInmAcM45F8kDhHPOuUgJDRAicrqILBORFSJyc8T6gSLyJxFZICLviMhhwfIxIvK6iCwRkcUi8q1EptM559y+EhYgRCQduA84A5gIXCIiE5tsdgtQoqqHA1cAdwfL64DvqOoE4FjgaxH7OuecS6BE1iCmAitUdZWq1gBPAuc22WYi8BqAqi4FxonIMFXdqKrvB8t3AUuAUQlMq3POuSYyEnjsUcC6mNelwDFNtpkPXAC8KSJTgbHAaGBzuIGIjAOOBN6OehMRuRa4FmDYsGEUFxd3TupTTEVFRa/NO3j+Pf+e/0TkP5EBQiKWaZPXdwB3i0gJsBD4AGtesgOI5AJ/BG5Q1Z1Rb6KqDwAPABQWFmpRUVGHE56KiouL6a15B8+/59/zn4j8JzJAlAJjYl6PBjbEbhAU+lcDiIgAq4MHIpKJBYfHVPW59iaitraW0tJSqqqq2nuIlDBgwACWLFnS5e+bk5PD6NGjyczM7PL3ds4lViIDxLvAQSJSAKwHLgYujd1ARPKByqCP4hpgjqruDILF/wJLVPXXHUlEaWkpeXl5jBs3Djtsz7Rr1y7y8vK69D1VlbKyMkpLSykoKOjS93bOJV7COqlVtQ74OjAL62R+WlUXi8j1InJ9sNkEYLGILMVGO4XDWY8DvgicLCIlweOz7UlHVVUVgwYN6tHBIVlEhEGDBvX42plzvVUiaxCo6svAy02W3R/zfC5wUMR+bxLdh9EuHhwSxz9b53ouv5LaOedcJA8QCVRWVsbkyZOZPHkyw4cPZ9SoUZ+8rqmpaXHfefPm8c1vfrOLUuqcc/tKaBNTbzdo0CBKSkoAuPXWW8nNzeW73/3uJ+vr6urIyIj+CgoLCyksLOyKZEaqr68nPT09ae/vnEu+3hUgbrgBggK700yeDHfdFffmV111Ffvttx8ffPABU6ZM4aKLLuKGG25gz5499OnThwcffJBDDjmE4uJifvWrX/HSSy9x6623snbtWlatWsXatWu54YYb9qld1NfXc9VVVzFv3jxEhC996UvceOONrFixguuvv56tW7eSnp7OM888w/jx47npppt45ZVXEBF+9KMfcdFFF1FcXMxtt93GiBEjKCkpYeHChdx8880UFxdTXV3N1772Na677rrO/fycc91W7woQ3cTy5ct59dVXSU9PZ+fOncyZM4eMjAxeffVVbrnlFv74xz/us8/SpUt5/fXX2bVrF4cccghf/epX97r2YMGCBaxfv55FixYBUF5eDsBll13GzTffzPnnn09VVRUNDQ0899xzlJSUMH/+fLZt28bRRx/NCSecAMA777zDokWLKCgo4IEHHmDAgAG8++67VFdXc9xxxzFjxgwf0upcL9G7AkQbzvQT6cILL/yk+WbHjh1ceeWVfPTRR4gItbW1kfuceeaZZGdnk52dzdChQ9m8eTOjR4/+ZP24ceNYtWoV3/jGNzjzzDOZMWMGu3btYv369Zx//vmAXdQG8Oabb3LJJZeQnp7OsGHDOPHEE3n33Xfp378/U6dO/SQAzJ49mwULFvDss89+ktaPPvrIA4RzvYR3UidBv379Pnn+4x//mJNOOolFixbx5z//udlrCrKzsz95np6eTl1d3V7rBw4cyPz58ykqKuK+++7jmmuuQbXpzCamueVN06aq3HvvvZSUlFBSUsLq1auZMWNGXHl0zqU+DxBJtmPHDkaNsolqH3rooXYfp6ysjIaGBj73uc9x++238/7779O/f39Gjx7N888/D0B1dTWVlZWccMIJPPXUU9TX17N161bmzJnD1KlT9znmaaedxm9/+9tPajXLly9n9+7d7U6jcy619K4mpm7opptu4sorr+TXv/41J598cruPs2HDBi644AIaGhoA+MUvfgHAI488wnXXXcdPfvITMjMzeeaZZzj//POZO3cuRxxxBCLCnXfeyfDhw1m6dOlex7zmmmtYs2YNU6ZMQVUZMmTIJ8HGOdfzSUvNDammsLBQ582bt9eyJUuWMGHChCSlqOskYy6mUHf4jH02T8+/57+oXfuKyHuqGjmm3puYnHPORfIA4ZxzLpIHCOecc5E8QDjnnIvkAcI551wkDxDOOeci+XUQCVRWVsYpp5wCwKZNm0hPT2fIkCGAzXmUlZXV4v7FxcVkZWUxffr0hKfVOeea8gCRQK1N992a4uJicnNzuyRAtDT1uHOud+pVJUI3mO2b9957j29/+9tUVFQwePBgHnroIUaMGME999zD/fffT0ZGBhMnTuSOO+7g/vvvJz09nUcffZR7772XT3/6058c54033uBb37JbeIsIf/nLX8jLy+POO+/kkUceIS0tjTPOOIM77riDkpISrr/+eiorKznggAOYOXMmAwcOpKioiOnTp/PWW29xzjnnUFRUFJk251zv1KsCRLKpKt/4xjd44YUXGDJkCE899RQ//OEPmTlzJnfccQerV68mOzub8vJy8vPzuf7665utdfzqV7/ivvvu47jjjqOiooLa2lpeeeUVnn/+ed5++2369u3L9u3bAbjiiiu49957OfHEE/nJT37Cbbfdxl1BVCsvL+eNN96gtraWE088MTJtzrneqVcFiGTP9l1dXc2iRYs49dRTAbvJT3iGfvjhh3PZZZdx3nnncd5557V6rOOOO45vf/vbXHbZZVxwwQUMGDCAV199lauvvpq+ffsCsN9++7Fjxw7Ky8s58cQTAbjyyiu58MILPznORRddBMCyZcuaTZtzrnfqVQEi2VSVSZMmMXfu3H3W/eUvf2HOnDm8+OKL3H777SxevLjFY918882ceeaZvPzyyxx77LG88MILqCoi0qY0hdN7t5Q251zv5MNcu1B2djZbt279pBCura1l8eLFNDQ0sG7dOk466STuvPNOysvLqaioIC8vj127dkUea+XKlXzqU5/i+9//PoWFhSxfvpwZM2Ywc+ZMKisrAdi+fTsDBgxg4MCB/P3vfwdsdtewNhHrkEMOiUybc6738hpEF0pLS+PZZ5/lm9/8Jjt27KCuro4bbriBgw8+mMsvv5wdO3agqtx4443k5+dz9tln8/nPf54XXnhhn07qu+66i9dff5309HQmTpzIqaeeyuDBgykpKaGwsJCsrCw++9nP8vOf/5w//OEPn3RSjx8/ngcffHCftGVlZUWmbdKkSV35ETnnuhGf7ruH8Om+fbpnz39RspORND7dt3POuS7lAcI551ykXhEgelIzWnfjn61zPVePDxA5OTmUlZV5QZYAqkpZWRk5OTnJTopzLgF6/Cim0aNHU1paytatW5OdlISqqqpKSkGdk5PD6NGju/x9nXOJ1+MDRGZmJgUFBclORsIVFxdz5JFHJjsZzrkeJKFNTCJyuogsE5EVInJzxPqBIvInEVkgIu+IyGHx7uuccy6xEhYgRCQduA84A5gIXCIiE5tsdgtQoqqHA1cAd7dhX+eccwmUyBrEVGCFqq5S1RrgSeDcJttMBF4DUNWlwDgRGRbnvs455xIokX0Qo4B1Ma9LgWOabDMfuAB4U0SmAmOB0XHuC4CIXAtcG7ysEJFlHU96ShoMbEt2IpLI8+/59/y3z9jmViQyQERNK9p0rOkdwN0iUgIsBD4A6uLc1xaqPgA80P5k9gwiMq+5y+V7A8+/59/z3/n5T2SAKAXGxLweDWyI3UBVdwJXA4jNU706ePRtbV/nnHOJlcg+iHeBg0SkQESygIuBF2M3EJH8YB3ANcCcIGi0uq9zzrnESlgNQlXrROTrwCwgHZipqotF5Ppg/f3ABOBhEakHPgS+3NK+iUprD9Hbm9k8/72b5z8BetR038455zpPj5+LyTnnXPt4gHDOORfJA0QKEJExIvK6iCwRkcUi8q1g+X4i8lcR+Sj4OzBmnx8E05QsE5HTkpf6ziMi6SLygYi8FLzuNfkPBnQ8KyJLg9/BtF6W/xuD3/4iEXlCRHJ6ev5FZKaIbBGRRTHL2pxnETlKRBYG6+4JRozGR1X90c0fwAhgSvA8D1iOXYV+J3BzsPxm4D+D5xOxixCzgQJgJZCe7Hx0wufwbeBx4KXgda/JP/AH4JrgeRaQ31vyj104uxroE7x+Griqp+cfOAGYAiyKWdbmPAPvANOw68teAc6INw1eg0gBqrpRVd8Pnu8ClmD/NOdiBQfB3/OC5+cCT6pqtaquBlZg05ekLBEZDZwJ/D5mca/Iv4j0xwqL/wVQ1RpVLaeX5D+QAfQRkQzsOqkN9PD8q+ocYHuTxW3Ks4iMAPqr6ly1aPFwzD6t8gCRYkRkHHAk8DYwTFU3ggURYGiwWdRUJaO6MJmJcBdwE9AQs6y35H88sBV4MGhi+72I9KOX5F9V1wO/AtYCG4EdqjqbXpL/Jtqa51HB86bL4+IBIoWISC7wR+AGtQsKm900YlnKjmcWkbOALar6Xry7RCxL2fxjZ89TgN+q6pHAbqx5oTk9Kv9BO/u5WNPJSKCfiFze0i4Ry1I2/3FqLs8d+iw8QKQIEcnEgsNjqvpcsHhzUIUk+LslWN7qNCcp5jjgHBFZg83se7KIPErvyX8pUKqqbwevn8UCRm/J/2eA1aq6VVVrgeeA6fSe/Mdqa55Lg+dNl8fFA0QKCEYd/C+wRFV/HbPqReDK4PmVwAsxyy8WkWwRKQAOwjqqUpKq/kBVR6vqOGzalb+p6uX0nvxvAtaJyCHBolOwmQd6Rf6xpqVjRaRv8L9wCtYP11vyH6tNeQ6aoXaJyLHBZ3dFzD6tS3ZPvT/iGs1wPFYtXACUBI/PAoOw+2l8FPzdL2afH2IjGZbRhlEL3f0BFNE4iqnX5B+YDMwLfgPPAwN7Wf5vA5YCi4BHsNE6PTr/wBNYn0stVhP4cnvyDBQGn9tK4DcEM2jE8/CpNpxzzkXyJibnnHORPEA455yL5AHCOedcJA8QzjnnInmAcM45F8kDhOtyIqIi8l8xr78rIrd20rEfEpHPd8axWnmfC4NZVV9vsrwonG02Yp/fi8jEiOVXichvmtmnonNS3DFd9bm67sUDhEuGauACERmc7ITEEpH0Nmz+ZeDfVPWkeHdQ1WtU9cO2p8y55PAA4ZKhDruH7o1NVzQ9Uw3PoIMz8zdE5GkRWS4id4jIZSLyTjDX/QExh/mMiPw92O6sYP90EfmliLwrIgtE5LqY474uIo8DCyPSc0lw/EUi8p/Bsp9gFy/eLyK/jMhfrjTeu+GxcP59ESkWkcLg+dVB+t7AphIJ369AROYG6by9SVq+F5P+24Jl44KazO/E7pcwW0T6NPO53iMi/xCRVeFnLOaXQf4WishFMct/IyIfishfaJwULry/wBsi8p6IzIqZ+uGbwfYLROTJiM/FpZpkXy3oj973ACqA/sAaYADwXeDWYN1DwOdjtw3+FgHl2L0xsoH1wG3Bum8Bd8Xs/3/Yyc9B2BWoOcC1wI+CbbKxq5ILguPuBgoi0jkSm+ZhCDZh3t+A84J1xUBhxD5FwA5szps0YC5wfOw+QR7C42YBbwG/CbZ5EbgieP61mPzPwIKqBMd9CZsCfBwWcCcH2z0NXB6RroeAZ4J9JwIrguWfA/4KpAPDgnSNAC6IWT4y+Ow/D2QC/wCGBPtfBMwMnm8AsoPn+cn+nfmj4w+vQbikUJuN9mHgm23Y7V21e2NUY9MGzA6WL8QKytDTqtqgqh8Bq4BDsQL2ChEpwaZKH4QFELA5a1ZHvN/RQLHaJHF1wGNYodyad1S1VFUbsGlRxjVZf0zMcWuAp2LWHYdNsQA2pURoRvD4AHg/yFOY/tWqWhI8fy/i/ULPB5/Lh1gwAKsJPaGq9aq6GXgjyPcJMcs3YMER4BDgMOCvwWf5Ixong1sAPCY202pdM2lwKSQj2QlwvdpdWGH3YMyyOoKmz6BpJitmXXXM84aY1w3s/VtuOn9MOO3xN1R1VuwKESnCahBR4r81495i01lP9P9ZS3PcRK0T4Beq+j97LbT7gzR9v32amCLSJU3+tiUdi1V1WsS6M7HAcg7wYxGZFARWl6K8BuGSRlW3Y00iX45ZvAY4Knh+Ltak0VYXikha0C8xHpu8bBbwVbFp0xGRg8VuutOSt4ETRWRw0IF9CXaG3VFvA0UiMihIz4Ux697CZqwFuCxm+SzgS2L3BEFERonIUDpuDnBR0EczBCvg3wmWXxwsHwGEnfHLgCEiMi1IR6aITBKRNGCMqr6O3dgpH8jthPS5JPIahEu2/wK+HvP6d8ALIvIONltlc2f3LVmGFeTDgOtVtUpEfo81vbwf1Ey20sqtF1V1o4j8AHgdO3N+WVXjnyq55ePeivVPbMRqUeEIqm8Bj4vIt7D7f4T7zBaRCcDcoM+7ArgcqzF0xJ+w+xXPx2oMN6nqJhH5E3Ay1ny3nCAwqmpN0MF9j4gMwMqQu4JtHg2WCfD/1G6L6lKYz+bqnHMukjcxOeeci+QBwjnnXCQPEM455yJ5gHDOORfJA4RzzrlIHiCcc85F8gDhnHMu0v8HpwfAB3tIc8sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최적의 은닉층의 노드 개수는 750 개입니다.\n",
      "\n",
      "[[71.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0. 73.  0.  0.  1.  0.  0.  0.  2.  0.]\n",
      " [ 0.  0. 75.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0. 63.  0.  0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0. 73.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 67.  1.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0. 74.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 68.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.  1.  0. 73.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0. 67.]]\n",
      "테스트 집합에 대한 정확률은 97.91376912378304 %입니다.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 데이터셋을 읽고 훈련 집합과 테스트 집합으로 분할\n",
    "digit=datasets.load_digits()\n",
    "x_train,x_test,y_train,y_test=train_test_split(digit.data,digit.target,train_size=0.6)\n",
    "\n",
    "# 다층 퍼셉트론을 교차 검증으로 성능 평가 (소요 시간 측정 포함)\n",
    "start=time.time()\n",
    "mlp=MLPClassifier(learning_rate_init=0.001,batch_size=32,max_iter=300,solver='sgd')\n",
    "prange=range(50,1001,50)\n",
    "train_score,test_score=validation_curve(mlp,x_train,y_train,param_name=\"hidden_layer_sizes\",param_range=prange,cv=10,scoring=\"accuracy\",n_jobs=4)\n",
    "end=time.time()\n",
    "print(\"하이퍼 매개변수 최적화에 걸린 시간은\",end-start,\"초입니다.\")\n",
    "\n",
    "# 교차 검증 결과의 평균과 분산 구하기\n",
    "train_mean= np.mean(train_score,axis=1)\n",
    "train_std = np.std(train_score,axis=1)\n",
    "test_mean = np.mean(test_score,axis=1)\n",
    "test_std = np.std(test_score,axis=1)\n",
    "\n",
    "#성능 그래프 그리기\n",
    "plt.plot(prange,train_mean,label=\"Train score\",color=\"r\")\n",
    "plt.plot(prange,test_mean,label=\"Test score\", color=\"b\")\n",
    "plt.fill_between(prange,train_mean-train_std,train_mean+train_std,alpha=0.2,color=\"r\")\n",
    "plt.fill_between(prange,test_mean-test_std,test_mean+test_std,alpha=0.2,color=\"b\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Validation Curve with MLP\")\n",
    "plt.xlabel(\"Number of hidden nodes\"); plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.9,1.01)\n",
    "plt.grid(axis='both')\n",
    "plt.show()\n",
    "\n",
    "best_number_nodes=prange[np.argmax(test_mean)] # 최적의 은닉 노드 개수\n",
    "print(\"\\n최적의 은닉층의 노드 개수는\",best_number_nodes,\"개입니다.\\n\")\n",
    "\n",
    "# 최적의 은닉 노드 개수로 모델링\n",
    "mlp_test=MLPClassifier(hidden_layer_sizes=(best_number_nodes),learning_rate_init=0.001,batch_size=32,max_iter=300,solver='sgd')\n",
    "mlp_test.fit(x_train,y_train)\n",
    "\n",
    "# 테스트 집합으로 예측\n",
    "res=mlp_test.predict(x_test)\n",
    "\n",
    "# 혼동 행렬\n",
    "conf=np.zeros((10,10))\n",
    "for i in range(len(res)):\n",
    "  conf[res[i]][y_test[i]]+=1\n",
    "print(conf)\n",
    "\n",
    "# 정확률 계산\n",
    "no_correct=0\n",
    "for i in range(10):\n",
    "  no_correct+=conf[i][i]\n",
    "accuracy=no_correct/len(res)\n",
    "print(\"테스트 집합에 대한 정확률은\",accuracy*100,\"%입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b23b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
